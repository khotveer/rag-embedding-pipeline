{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411068c-8a3e-47c0-ba40-5f0fc2b43f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5101b441-8773-4159-8add-afb004db623f",
   "metadata": {},
   "source": [
    "### Loading llm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e5056de-e9ec-48c2-9d2e-be77f06d1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78fbf28e-e73f-4f02-aad2-ab77ad09d2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d762e32ff8f46f3bc2f41c23fd3a012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Set the model name\n",
    "model_name = \"google/gemma-2b-it\"\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Step 2: Load tokenizer and fix padding side (Gemma requires left-padding for generation)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"  # Gemma needs left padding for batched generation\n",
    "\n",
    "# Step 3: Load model directly onto GPU\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",       # or omit this if issues arise\n",
    "    device_map=None           # Don't use device_map on CPU\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    top_p=1.0,\n",
    "    do_sample=False       # Disable sampling; forces greedy decoding\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d5d26-afba-44e1-99d3-0da1b82fa6e0",
   "metadata": {},
   "source": [
    "### Loading the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d956ed-b7e8-4486-99d8-512ea4d4750f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\khotv\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b7ba1a-5cae-4c38-953f-c12b92e94280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khotv\\AppData\\Local\\Temp\\ipykernel_13256\\2313736344.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_fn = HuggingFaceEmbeddings(\n",
      "C:\\Users\\khotv\\AppData\\Local\\Temp\\ipykernel_13256\\2313736344.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_fn = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-base-en-v1.5\"\n",
    ")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    client=chromadb.PersistentClient(path=\"./chroma_bge_768\"),\n",
    "    collection_name=\"qnotes_docs\",\n",
    "    embedding_function=embedding_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d43e9-3342-4169-b23e-8432627dbaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f93795-83d9-4f8a-b68c-d0c0f803a88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khotv\\AppData\\Local\\Temp\\ipykernel_13256\\1388542332.py:2: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "# pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512)\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cefffdd-c301-4ff3-a6af-1cf44ead36cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a0cddce-495f-4ad3-a50b-d61afa3ff024",
   "metadata": {},
   "source": [
    "### Retriver using prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997412f7-82bf-4df3-844b-b52587b2a8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pathlib\n",
    "sys.path.insert(0, os.path.abspath(\"src\"))        # points to ./src relative to the notebook\n",
    "\n",
    "from src.quantum_router import pick_quantum_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b34983-ed74-407f-9fa0-69013d1ee365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(user_query, vectorstore, sample_no = 1):\n",
    "\n",
    "    # Use your vectorstore to get context\n",
    "    retrieved_docs = vectorstore.similarity_search(user_query, k=7)\n",
    "\n",
    "    retrieved_context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "    template_fn = pick_quantum_template(user_query)\n",
    "\n",
    "    prompt = template_fn(retrieved_context, user_query)\n",
    "\n",
    "    \n",
    "    # Run with Gemma or Mistral\n",
    "    output = pipe(prompt)[0]['generated_text']\n",
    "\n",
    "    answer = output.split(\"Answer (structured and accurate):\")[-1].strip()\n",
    "    context = output.split(\"Context:\")[-1].strip().split(\"Question:\")[0].strip()\n",
    "    question = output.split(\"Question:\")[-1].strip().split(\"Answer (structured and accurate):\")[0].strip()\n",
    "    \n",
    "    result = {\n",
    "        \"question\": question,\n",
    "        \"context\": context,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "    \n",
    "    print(\"sample\"+str(sample_no))\n",
    "    print(\"question: \", result[\"question\"])\n",
    "    print(\"answer: \", result[\"answer\"])\n",
    "    print()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d7dfe6c-414b-4ef1-ac86-3311852f10b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = ['What are three reasons to study quantum computers?',\n",
    " 'What is the purpose of the Hadamard gate in quantum computing?',\n",
    " 'What is the standard form of an EPR-pair? Also include equation',\n",
    " 'Who proposed the first efficient quantum algorithm for factoring, and in what year?',\n",
    " 'What is the role of the quantum circuit model in computation?',\n",
    " 'How can an EPR-pair simulate a public coin toss?',\n",
    " 'What is the function of the Toffoli gate, and why is it important?',\n",
    " 'What does the Quantum Fourier Transform do in phase estimation?',\n",
    " 'What is the difference between the quantum Turing machine and the quantum circuit model?',\n",
    " 'Why did Feynman propose the idea of quantum computers?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5638714f-5981-49c4-8b6f-93f0c14d823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample0\n",
      "question:  What are three reasons to study quantum computers?\n",
      "answer:  1. The process of miniaturization that has made current classical computers so powerful and cheap, has already reached micro-levels where quantum eﬀects occur.\n",
      "2. Making use of quantum eﬀects allows one to speed up certain computations enormously (sometimes exponentially), and even enables some things that are impossible for classical computers.\n",
      "3. The main goal of theoretical computer science is to “study the power and limitations of the strongest-possible computational devices that Nature allows us.”\n",
      "\n",
      "-------------------------------------------------------------\n",
      "sample1\n",
      "question:  What is the purpose of the Hadamard gate in quantum computing?\n",
      "answer:  The purpose of the Hadamard gate in quantum computing is to apply a quantum operation on each qubit in the register, resulting in a superposition of all n-bit strings. This allows quantum algorithms to explore a vast number of different possibilities simultaneously, leading to potential breakthroughs in various fields such as drug discovery, materials science, and cryptography.\n",
      "\n",
      "-------------------------------------------------------------\n",
      "sample2\n",
      "question:  What is the standard form of an EPR-pair? Also include equation\n",
      "answer:  **Standard form of an EPR-pair:**\n",
      "|φ⟩ = 1/√2(|00⟩ + |11⟩)\n",
      "\n",
      "**Equation:**\n",
      "1\n",
      "√\n",
      "2(|00⟩+ |11⟩) = 1/√2(|00⟩ − |11⟩)\n",
      "\n",
      "-------------------------------------------------------------\n",
      "sample3\n",
      "question:  Who proposed the first efficient quantum algorithm for factoring, and in what year?\n",
      "answer:  According to the context, the first efficient quantum algorithm for factoring was proposed by Peter Shor in 1994.\n",
      "\n",
      "-------------------------------------------------------------\n",
      "sample4\n",
      "question:  What is the role of the quantum circuit model in computation?\n",
      "answer:  The quantum circuit model is a way of representing quantum circuits that is more efficient than the quantum Turing machine model. It is a model that can be used to simulate quantum circuits in polynomial time.\n",
      "\n",
      "-------------------------------------------------------------\n",
      "sample5\n",
      "question:  How can an EPR-pair simulate a public coin toss?\n",
      "answer:  An EPR-pair can simulate a public coin toss by measuring the state of one qubit and using that information to determine the state of the other qubit.\n",
      "\n",
      "-------------------------------------------------------------\n",
      "sample6\n",
      "question:  What is the function of the Toffoli gate, and why is it important?\n",
      "answer:  Sure, here's the answer to the question:\n",
      "\n",
      "The Toﬀoli gate is a 3-qubit gate that negates the third bit of its input if both of the first two bits are 1. It is important because it is complete for classical reversible computation, meaning that any classical computation can be implemented by a circuit of Toﬀoli gates.\n",
      "\n",
      "-------------------------------------------------------------\n",
      "sample7\n",
      "question:  What does the Quantum Fourier Transform do in phase estimation?\n",
      "answer:  Sure, here's the answer to the question:\n",
      "\n",
      "The Quantum Fourier Transform (QFT) in phase estimation transforms the copy of ρ and a few auxiliary |0⟩-qubits into the state |cj⟩⊗|λj⟩with probability λj.5.\n",
      "\n",
      "-------------------------------------------------------------\n",
      "sample8\n",
      "question:  What is the difference between the quantum Turing machine and the quantum circuit model?\n",
      "answer:  Sure, here's the difference between the quantum Turing machine and the quantum circuit model:\n",
      "\n",
      "- The quantum Turing machine uses a quantum circuit for each new input length, while the quantum circuit model uses a quantum circuit for each fixed input length.\n",
      "- The quantum Turing machine can simulate any quantum algorithm, while the quantum circuit model can only simulate a subset of quantum algorithms.\n",
      "\n",
      "-------------------------------------------------------------\n",
      "sample9\n",
      "question:  Why did Feynman propose the idea of quantum computers?\n",
      "answer:  According to the context, Feynman proposed the idea of quantum computers because he believed that a quantum computer could be used to simulate other quantum systems, which was a key motivation for the development of quantum computing.\n",
      "\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, q in enumerate(qs):\n",
    "    retriever(q, vectorstore, sample_no = i)\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f15f74-966c-412d-b1f8-0a5d0a015a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70eca36-a2d3-42b2-bcd2-17b606c5895f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm_v3)",
   "language": "python",
   "name": "llm_v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
