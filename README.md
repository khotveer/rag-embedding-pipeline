# RAG Embedding Pipeline: Quantum Notes QA
![Architecture Diagram](./assets/RAG_architecture.gif)

> A minimal, production-ready Retrieval-Augmented Generation (RAG) pipeline built on quantum computing lecture notes â€” powered by embedding models and an LLM backend.
---

## ğŸ“Œ Project Purpose

This project demonstrates an end-to-end **RAG (Retrieval-Augmented Generation)** setup using a knowledge base of **Quantum Computing notes**. It allows you to ask questions in natural language, retrieve relevant document chunks using semantic search, and generate meaningful answers with an LLM.

The goal is to showcase a lightweight, modular, and practical example of how RAG works in real-world scenarios.

---

## ğŸš€ Features

- ğŸ§  Embeddings via [`BAAI/bge-base-en-v1.5`](https://huggingface.co/BAAI/bge-base-en-v1.5)
- ğŸ—‚ï¸ Vector store using **ChromaDB**
- ğŸ§¾ Knowledge base built from structured quantum lecture notes
- ğŸ” Contextual search for relevant text chunks
- ğŸ¤– Response generation with [`google/gemma-2b-it`](https://huggingface.co/google/gemma-2b-it)
- ğŸŒ Flask-based API backend (`flask_app/`)
- ğŸ’» Minimal UI using Streamlit (`ui/`)
- ğŸ³ Docker support for containerized execution

---
## ğŸ§± Folder Structure
```
.
â”œâ”€â”€ flask_app/ # Flask backend for LLM-based querying
â”œâ”€â”€ ui/ # Streamlit UI for interactive RAG querying
â”œâ”€â”€ data/ # Source quantum notes / documents
â”œâ”€â”€ chroma_bge_768/ # ChromaDB vector store (populated with BGE embeddings)
â”œâ”€â”€ src/ # Embedding & retrieval logic
â”œâ”€â”€ app.py # Entrypoint (for inference)
â”œâ”€â”€ requirements_llm_v3.txt
```
---
## ğŸ“’ Notebooks Overview

This project includes two Jupyter notebooks for development, experimentation, and debugging:

### ğŸ“˜ `01-rag-pipeline-setting.ipynb`
- Used for end-to-end experimentation with vector DB creation
- Loads and splits the quantum notes
- Generates embeddings using `BAAI/bge-base-en-v1.5`
- Saves the processed data to ChromaDB
- Explores basic prompt structuring and QA via local functions

### ğŸ“™ `02-rag-inference-pipeline.ipynb`
- Uses the vector DB created earlier
- Loads and tests the RAG pipeline with stored embeddings
- Sends context to the LLM (`google/gemma-2b-it`) with different prompts
- Mimics what the production `app.py` does


> âœ… `app.py` is a productionized version of the logic used in the second notebook.

---


## ğŸ³ How to Run with Docker

> Make sure Docker is installed and Hugging Face models are downloaded locally.

---

### ğŸ“¥ Step 1: Clone and Enter the Flask App Folder

```bash
git clone https://github.com/khotveer/rag-embedding-pipeline.git
cd rag-embedding-pipeline/flask_app
```
Then, open **config.py** and add your Hugging Face token:
```python
# config.py
hugging_face_token = "your_huggingface_token_here"
```


### ğŸ“¦ Step 2: Download Required Models from Hugging Face

Before building Docker, manually download these models locally:

- Embedding Model: BAAI/bge-base-en-v1.5
- LLM Model: google/gemma-2b-it

They will be saved to: ~/.cache/huggingface on your machine.

### ğŸ³ Step 3: Build and Run the Docker Container
```bash 
# Build the container
docker build -t quantum_notes_rag .

# Run the container with mounted model cache
docker run -p 5000:5000 -v "$HOME/.cache/huggingface:/root/.cache/huggingface" quantum_notes_rag
```
- Flask API will be available at: http://localhost:5000/query
- Models will load faster using the shared local cache.

## ğŸ’» Streamlit UI (`/ui` folder)

A minimal UI built with **Streamlit** allows interactive querying of the RAG pipeline.

### ğŸ”§ How to Run the Streamlit App

From the project root:

```bash
cd ui
streamlit run streamlit_app.py --server.port 7860
```

---

## ğŸ–¼ï¸ Screenshots

### ğŸ§  Streamlit UI: Home Page
![UI Home](./assets/ui_landing_page.png)

---

### ğŸ“ Sample Query & Answer

![Query Result](./assets/first_example.png)

![Query Result](./assets/second_example.png)
---


## ğŸ”— Connect with Me

If you're interested in RAG pipelines, LLM integration, or applied AI projects, feel free to connect:

**ğŸ”— [Veer Khot on LinkedIn](https://www.linkedin.com/in/veer-khot-93177bab/)**

---


